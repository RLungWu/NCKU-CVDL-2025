import numpy as np
import random
import torch
import torch.nn as nn
import torch.optim as optim
import cv2

# ==================== HYPERPARAMETERS TABLE ====================
# èª¿æ•´æ­¤è¡¨æ ¼ä¾†ä¿®æ”¹æ‰€æœ‰çå‹µ/æ‡²ç½°çš„æ•¸å€¼
# Adjust this table to modify all reward/penalty values
# ===============================================================

# ğŸ”¥ åˆ‡æ›æ¨¡å¼ï¼šTrue = æ¥µç«¯æ¨¡å¼, False = æ­£å¸¸æ¨¡å¼
EXTREME_MODE = True

# ===== æ­£å¸¸æ¨¡å¼ (Normal Mode) =====
NORMAL_CONFIG = {
    "coin_reward": 5,               # æ”¶é›†ç¡¬å¹£çå‹µ
    "jump_reward": 10,              # è·³èºçå‹µ
    "forward_reward": 10,           # å‰é€²çå‹µ
    "score_reward": 8,              # æ“Šæ•—æ•µäººçå‹µ
    "flag_reward": 100,             # çµ‚é»çå‹µ
    "life_bonus": 50,               # 1UPçå‹µ
    "fall_penalty": -10,            # ä¸‹è½æ‡²ç½°
    "backward_penalty": -10,        # å¾Œé€€æ‡²ç½°
    "no_score_penalty": -10,        # ç„¡å¾—åˆ†æ‡²ç½°
    "death_penalty": -100,          # æ­»äº¡æ‡²ç½°
    "stagnation_penalty": -5,       # åœæ»¯æ‡²ç½°
    "time_waste_penalty": -5,       # æ™‚é–“æµªè²»æ‡²ç½°
    "time_waste_threshold": 3,
}

# ===== æ¥µç«¯æ¨¡å¼ (EXTREME Mode) - æ›´å¼·çƒˆçš„çæ‡²è¨Šè™Ÿ =====
EXTREME_CONFIG = {
    "coin_reward": 50,              # ç¡¬å¹£çå‹µ x10
    "jump_reward": 30,              # è·³èºçå‹µ x3
    "forward_reward": 50,           # å‰é€²çå‹µ x5 (æœ€é‡è¦!)
    "score_reward": 40,             # æ“Šæ•—æ•µäºº x5
    "flag_reward": 1000,            # çµ‚é»çå‹µ x10
    "life_bonus": 200,              # 1UPçå‹µ x4
    "fall_penalty": -20,            # ä¸‹è½æ‡²ç½° x2
    "backward_penalty": -50,        # å¾Œé€€æ‡²ç½° x5 (å¼·çƒˆé˜»æ­¢å¾Œé€€!)
    "no_score_penalty": 0,          # ä¸æ‡²ç½°ç„¡å¾—åˆ† (æ¸›å°‘å™ªéŸ³)
    "death_penalty": -500,          # æ­»äº¡æ‡²ç½° x5
    "stagnation_penalty": -30,      # åœæ»¯æ‡²ç½° x6 (å¼·çƒˆé˜»æ­¢åŸåœ°ä¸å‹•!)
    "time_waste_penalty": -20,      # æ™‚é–“æµªè²»æ‡²ç½° x4
    "time_waste_threshold": 2,      # æ›´åš´æ ¼çš„æ™‚é–“é–¾å€¼
}

# æ ¹æ“šæ¨¡å¼é¸æ“‡é…ç½®
REWARD_CONFIG = EXTREME_CONFIG if EXTREME_MODE else NORMAL_CONFIG

print(f"ğŸ® Reward Mode: {'ğŸ”¥ EXTREME' if EXTREME_MODE else 'ğŸ“Š NORMAL'}")

# Env state 
# info = {
#     "x_pos",  # (int) The player's horizontal position in the level.
#     "y_pos",  # (int) The player's vertical position in the level.
#     "score",  # (int) The current score accumulated by the player.
#     "coins",  # (int) The number of coins the player has collected.
#     "time",   # (int) The remaining time for the level.
#     "flag_get",  # (bool) True if the player has reached the end flag (level completion).
#     "life"   # (int) The number of lives the player has left.
# }


# # simple actions_dim = 7 
# SIMPLE_MOVEMENT = [
#     ["NOOP"],       # Do nothing.
#     ["right"],      # Move right.
#     ["right", "A"], # Move right and jump.
#     ["right", "B"], # Move right and run.
#     ["right", "A", "B"], # Move right, run, and jump.
#     ["A"],          # Jump straight up.
#     ["left"],       # Move left.
# ]
#-----------------------------------------------------------------------------
#çå‹µå‡½æ•¸
'''
get_coin_reward         : æ ¹æ“šç¡¬å¹£æ•¸é‡è®ŠåŒ–æä¾›é¡å¤–çå‹µ

'''
'''
ç’°å¢ƒè³‡è¨Š (info)
1."x_pos": æ°´å¹³ä½ç½®ï¼Œç”¨æ–¼åˆ¤æ–·è§’è‰²çš„å‰é€²æƒ…æ³
2."y_pos": å‚ç›´ä½ç½®ï¼Œç”¨æ–¼åˆ†æè·³èºæˆ–ä¸‹è½è¡Œç‚º
3."score": ç©å®¶ç›®å‰çš„éŠæˆ²åˆ†æ•¸
4."coins": æ”¶é›†åˆ°çš„ç¡¬å¹£æ•¸é‡
5."time": å‰©é¤˜æ™‚é–“
5."flag_get": æ˜¯å¦åˆ°é”çµ‚é»æ——å¹Ÿï¼ˆéŠæˆ²å®Œæˆï¼‰
6."life": ç©å®¶å‰©é¤˜çš„ç”Ÿå‘½æ•¸
'''

#===============to do===============================è«‹è‡ªå®šç¾©çå‹µå‡½æ•¸ è‡³å°‘7å€‹(åŒ…å«æä¾›çš„)

#ä¾‹å­:ç”¨ä¾†çå‹µç©å®¶è’é›†ç¡¬å¹£çš„è¡Œç‚º
def get_coin_reward(info, reward, prev_info):
    #å¯«ä¸‹è’é›†åˆ°ç¡¬å¹£æœƒå°æ‡‰å¤šå°‘çå‹µ
    total_reward = reward                                         #ç²å¾—ç›®å‰å·²æœ‰çš„çå‹µæ•¸é‡
    total_reward += (info['coins'] - prev_info['coins']) * REWARD_CONFIG["coin_reward"]
    return total_reward

#ç”¨ä¾†é¼“å‹µç©å®¶é€²è¡Œè·³èºæˆ–é«˜åº¦è®ŠåŒ–(å› ç‚ºæœ‰æ™‚å‰æ–¹æœ‰éšœç¤™ç‰© æœƒè¢«å¡ä½)
def distance_y_offset_reward(info, reward, prev_info):
    if info['y_pos'] - prev_info['y_pos'] > 0:
        return REWARD_CONFIG["jump_reward"]
    else:
        return REWARD_CONFIG["fall_penalty"]

#ç”¨ä¾†é¼“å‹µç©å®¶å‰é€²ï¼Œæ‡²ç½°åŸåœ°åœç•™æˆ–å¾Œé€€
def distance_x_offset_reward(info, reward, prev_info):
    if info['x_pos'] - prev_info['x_pos'] > 0:
        return REWARD_CONFIG["forward_reward"]
    else:
        return REWARD_CONFIG["backward_penalty"]

#ç”¨ä¾†é¼“å‹µç©å®¶æé«˜åˆ†æ•¸ï¼ˆä¾‹å¦‚æ“Šæ•—æ•µäºº)
def monster_score_reward(info, reward, prev_info):
    if info['score'] - prev_info['score'] > 0:
        return REWARD_CONFIG["score_reward"]
    else:
        return REWARD_CONFIG["no_score_penalty"]

#ç”¨ä¾†é¼“å‹µç©å®¶å®Œæˆé—œå¡ï¼ˆåˆ°é”çµ‚é»æ——å¹Ÿï¼‰
def final_flag_reward(info,reward):
    if info['flag_get']:
        return REWARD_CONFIG["flag_reward"]
    else:
        return 0



#===============to do==========================================

# 6. æ™‚é–“æ•ˆç‡çå‹µï¼šé¼“å‹µç©å®¶åœ¨æœ‰é™æ™‚é–“å…§å¿«é€Ÿé€šé—œ
def time_efficiency_reward(info, reward, prev_info):
    """
    æ ¹æ“šå‰©é¤˜æ™‚é–“çµ¦äºˆçå‹µï¼Œæ™‚é–“è¶Šå¤šä»£è¡¨ç©å®¶æ•ˆç‡è¶Šé«˜
    æ™‚é–“æ¸›å°‘éå¿«æœƒå—åˆ°æ‡²ç½°
    """
    time_diff = prev_info['time'] - info['time']
    if time_diff > REWARD_CONFIG["time_waste_threshold"]:
        return REWARD_CONFIG["time_waste_penalty"]
    return 0

# 7. æ­»äº¡æ‡²ç½°ï¼šç©å®¶å¤±å»ç”Ÿå‘½æ™‚çµ¦äºˆå¤§é‡æ‡²ç½°
def death_penalty(info, reward, prev_info):
    """
    ç•¶ç©å®¶å¤±å»ç”Ÿå‘½æ™‚çµ¦äºˆåš´é‡æ‡²ç½°
    é€™æœƒè®“ AI å­¸ç¿’é¿å…å±éšªæƒ…æ³
    """
    if info['life'] < prev_info['life']:
        return REWARD_CONFIG["death_penalty"]
    return 0

# 8. åœæ»¯æ‡²ç½°ï¼šæ‡²ç½°é•·æ™‚é–“åœç•™åœ¨åŒä¸€ä½ç½®
def stagnation_penalty(info, reward, prev_info):
    """
    å¦‚æœç©å®¶çš„ x ä½ç½®æ²’æœ‰è®ŠåŒ–ï¼Œçµ¦äºˆå°æ‡²ç½°
    é¼“å‹µæŒçºŒå‰é€²
    """
    if info['x_pos'] == prev_info['x_pos']:
        return REWARD_CONFIG["stagnation_penalty"]
    return 0

# 9. ç”Ÿå‘½çå‹µï¼šçå‹µç©å®¶ç²å¾—é¡å¤–ç”Ÿå‘½ï¼ˆå¦‚åƒåˆ°1UPè˜‘è‡ï¼‰
def life_bonus_reward(info, reward, prev_info):
    """
    ç•¶ç©å®¶ç²å¾—é¡å¤–ç”Ÿå‘½æ™‚çµ¦äºˆçå‹µ
    é¼“å‹µç©å®¶å°‹æ‰¾éš±è—çš„1UPçå‹µ
    """
    if info['life'] > prev_info['life']:
        return REWARD_CONFIG["life_bonus"]
    return 0







# ==============to do========================================
def final_reward(info,reward, prev_info):
    final_reward = 0
    # åŸæœ‰çš„ 5 å€‹çå‹µå‡½æ•¸
    final_reward += get_coin_reward(info, reward, prev_info)
    final_reward += distance_y_offset_reward(info, reward, prev_info)
    final_reward += distance_x_offset_reward(info, reward, prev_info)
    final_reward += monster_score_reward(info, reward, prev_info)
    final_reward += final_flag_reward(info, reward)
    
    # æ–°å¢çš„ 4 å€‹çå‹µ/æ‡²ç½°å‡½æ•¸
    final_reward += time_efficiency_reward(info, reward, prev_info)  # æ™‚é–“æ•ˆç‡çå‹µ
    final_reward += death_penalty(info, reward, prev_info)           # æ­»äº¡æ‡²ç½°
    final_reward += stagnation_penalty(info, reward, prev_info)      # åœæ»¯æ‡²ç½°
    final_reward += life_bonus_reward(info, reward, prev_info)       # ç”Ÿå‘½çå‹µ
    
    return final_reward


