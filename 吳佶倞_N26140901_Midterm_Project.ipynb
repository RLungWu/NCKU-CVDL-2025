{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RLungWu/NCKU-CVDL-2025/blob/main/%E5%90%B3%E4%BD%B6%E5%80%9E_N26140901_Midterm_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0314b3a",
      "metadata": {
        "id": "c0314b3a"
      },
      "source": [
        "### Theme1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "279acd97",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "279acd97",
        "outputId": "6c1a5e57-3fd9-497d-ad79-df5f2854e1bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ed8a3144",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed8a3144",
        "outputId": "1c7e8cd2-ae89-409a-8b5c-a5b93338ee1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Nov 27 08:51:40 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P8             11W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb39f883",
      "metadata": {
        "id": "cb39f883"
      },
      "source": [
        "#### Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e734d54c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e734d54c",
        "outputId": "3220d33a-0814-40cd-8a03-7eed942561eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'rock-paper-scissors-dataset' dataset.\n",
            "Path to dataset files: /kaggle/input/rock-paper-scissors-dataset\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"sanikamal/rock-paper-scissors-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### v2 test"
      ],
      "metadata": {
        "id": "CAbHrxXyfcDA"
      },
      "id": "CAbHrxXyfcDA"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# ==========================================\n",
        "# 1. 全域設定 (極限效能版)\n",
        "# ==========================================\n",
        "# 如果路徑不同請自行修改\n",
        "#path = \"/content/Rock-Paper-Scissors\"\n",
        "\n",
        "root = Path(path) / \"Rock-Paper-Scissors\"\n",
        "\n",
        "SEED = 77\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# RAM 若足夠大，設 dataset 大小；否則設 1000 左右\n",
        "SHUFFLE_BUFFER = 1000\n",
        "\n",
        "# [極限優化] 暴力拉大 Batch Size 以填滿 VRAM\n",
        "# 如果 VRAM OOM，請降為 128 或 64\n",
        "BATCH_SIZE = 64\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "# 開啟混合精度加速 (VRAM 省一半，速度變快)\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# ==========================================\n",
        "# 2. 資料集準備 (修正 Validation 結構)\n",
        "# ==========================================\n",
        "\n",
        "# --- A. 建立 Train/Test 的 file list ---\n",
        "train_dir = root / \"train\"\n",
        "test_dir = root / \"test\"\n",
        "\n",
        "# 使用 tf.keras.utils.image_dataset_from_directory 雖然方便，\n",
        "# 但為了實作 uint8 trick，我們改用底層 API 手動控制流程，這樣最穩。\n",
        "# 這裡我們只抓路徑，不做讀取。\n",
        "train_ds_raw = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=None, # 設為 None 以獲得單張圖片的 dataset，方便我們自定義 pipeline\n",
        "    shuffle=True,\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "test_ds_raw = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=None,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# --- B. 修正 Validation Pipeline (Pure TF) ---\n",
        "# 解決你原本 RAM 壓力的核心：不使用 Python Loop 和 py_function\n",
        "label_map = {\"rock\": 0, \"paper\": 1, \"scissors\": 2}\n",
        "val_files = sorted((root / \"validation\").glob(\"*.png\"))\n",
        "\n",
        "val_paths = []\n",
        "val_labels = []\n",
        "\n",
        "print(f\"正在解析 Validation 檔案... 共 {len(val_files)} 張\")\n",
        "for p in val_files:\n",
        "    name = p.name.lower()\n",
        "    found = False\n",
        "    for cls_name, idx in label_map.items():\n",
        "        if cls_name in name:\n",
        "            val_paths.append(str(p))\n",
        "            val_labels.append(idx)\n",
        "            found = True\n",
        "            break\n",
        "    if not found:\n",
        "        print(f\"Warning: 無法識別類別 - {p.name}\")\n",
        "\n",
        "# 建立純文字路徑的 dataset\n",
        "val_ds_paths = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\n",
        "\n",
        "# 定義讀取函數 (Pure TF) - 這是 Validation 專用的讀取器\n",
        "def load_val_image(path, label):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.io.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, IMG_SIZE)\n",
        "    # 統一轉為 uint8，對齊 Train 的格式\n",
        "    img = tf.cast(img, tf.uint8)\n",
        "    return img, label\n",
        "\n",
        "val_ds_raw = val_ds_paths.map(load_val_image, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "# ==========================================\n",
        "# 3. 核心優化 Pipeline (The uint8 Trick)\n",
        "# ==========================================\n",
        "\n",
        "# 定義 Augmentation (只在 GPU/Float 階段執行)\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomRotation(0.1),\n",
        "    tf.keras.layers.RandomZoom(0.1),\n",
        "    tf.keras.layers.RandomContrast(0.15),\n",
        "    tf.keras.layers.RandomBrightness(factor=0.1),\n",
        "])\n",
        "\n",
        "def apply_pipeline(ds, training=False):\n",
        "    # 【階段 1】：前處理 (Pre-Cache)\n",
        "    # 如果是 image_dataset_from_directory 出來的資料已經是 float32，我們要轉回 uint8\n",
        "    def to_uint8(img, label):\n",
        "        img = tf.cast(img, tf.uint8)\n",
        "        # 確保 resize 是正確的 (雙重保險)\n",
        "        img = tf.image.resize(img, IMG_SIZE)\n",
        "        img = tf.cast(img, tf.uint8)\n",
        "        return img, label\n",
        "\n",
        "    ds = ds.map(to_uint8, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "    # 【階段 2】：Cache (關鍵！)\n",
        "    # 此時記憶體中存的是 uint8 (體積只有 float32 的 1/4)\n",
        "    # 這樣你可以放心 cache 而不爆 RAM\n",
        "    ds = ds.cache()\n",
        "\n",
        "    # 【階段 3】：Shuffle (只對 Training)\n",
        "    if training:\n",
        "        ds = ds.shuffle(SHUFFLE_BUFFER, seed=SEED, reshuffle_each_iteration=True)\n",
        "\n",
        "    # 【階段 4】：後處理 (Post-Cache) - 轉 Float、歸一化、Augmentation\n",
        "    def process_on_gpu(img, label):\n",
        "        # 轉回 Float32\n",
        "        img = tf.cast(img, tf.float32)\n",
        "        # 歸一化 (0~1)\n",
        "        img = img / 255.0\n",
        "\n",
        "        if training:\n",
        "            # Augmentation 必須在 float32 下進行\n",
        "            img = data_augmentation(img, training=True)\n",
        "        return img, label\n",
        "\n",
        "    # 進行 batching，然後再做 GPU 運算\n",
        "    ds = ds.batch(BATCH_SIZE)\n",
        "    ds = ds.map(process_on_gpu, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "    # 【階段 5】：Prefetch\n",
        "    ds = ds.prefetch(AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "print(\"正在建構高效能 Pipeline...\")\n",
        "train_ds = apply_pipeline(train_ds_raw, training=True)\n",
        "val_ds   = apply_pipeline(val_ds_raw, training=False)\n",
        "test_ds  = apply_pipeline(test_ds_raw, training=False)\n",
        "print(\"Pipeline 建構完成。\")\n",
        "\n",
        "# ==========================================\n",
        "# 4. 模型與訓練 (XLA 加速)\n",
        "# ==========================================\n",
        "\n",
        "def build_scratch_model(input_shape=(*IMG_SIZE, 3), num_classes=3):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "    # 因為我們在 pipeline 做了 /255.0，這裡不需要再 Rescaling\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(24, 3, padding=\"same\")(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    x = tf.keras.layers.MaxPool2D()(x)\n",
        "\n",
        "    for filters in [64, 128, 256]:\n",
        "        x = tf.keras.layers.Conv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        x = tf.keras.layers.ReLU()(x)\n",
        "        x = tf.keras.layers.Conv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        x = tf.keras.layers.ReLU()(x)\n",
        "        x = tf.keras.layers.MaxPool2D()(x)\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.Dropout(0.4)(x)\n",
        "\n",
        "    # 確保輸出層是 float32 (為了 Mixed Precision 穩定性)\n",
        "    outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\", dtype='float32')(x)\n",
        "    return tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model = build_scratch_model()\n",
        "\n",
        "# 編譯模型：開啟 XLA (jit_compile=True)\n",
        "# 根據 Batch Size 256 調整 Learning Rate\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=2e-3), # 稍微調高 LR\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=[\"accuracy\"],\n",
        "    jit_compile=True # <--- 核武器：XLA 編譯加速\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        \"scratch_best.keras\",\n",
        "        monitor=\"val_accuracy\",\n",
        "        save_best_only=True\n",
        "    ),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-5\n",
        "    ),\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\", patience=10, restore_best_weights=True\n",
        "    )\n",
        "]\n",
        "\n",
        "print(f\"開始訓練... Batch Size: {BATCH_SIZE}, XLA: Enabled\")\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=40,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OF-PPbGefb3C",
        "outputId": "61cedf10-05ed-4d28-95aa-9b997877a527"
      },
      "id": "OF-PPbGefb3C",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2520 files belonging to 3 classes.\n",
            "Found 372 files belonging to 3 classes.\n",
            "正在解析 Validation 檔案... 共 33 張\n",
            "正在建構高效能 Pipeline...\n",
            "Pipeline 建構完成。\n",
            "開始訓練... Batch Size: 64, XLA: Enabled\n",
            "Epoch 1/40\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - accuracy: 0.3344 - loss: 1.3825 - val_accuracy: 0.3333 - val_loss: 1.3705 - learning_rate: 0.0020\n",
            "Epoch 2/40\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 888ms/step - accuracy: 0.3273 - loss: 1.1443 - val_accuracy: 0.3939 - val_loss: 1.1005 - learning_rate: 0.0020\n",
            "Epoch 3/40\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 858ms/step - accuracy: 0.3372 - loss: 1.1296 - val_accuracy: 0.4545 - val_loss: 1.0984 - learning_rate: 0.0020\n",
            "Epoch 4/40\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 863ms/step - accuracy: 0.3229 - loss: 1.1289 - val_accuracy: 0.3333 - val_loss: 1.1000 - learning_rate: 0.0020\n",
            "Epoch 5/40\n",
            "\u001b[1m32/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m7s\u001b[0m 876ms/step - accuracy: 0.3276 - loss: 1.1277"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FKZxwGSBfb0H"
      },
      "id": "FKZxwGSBfb0H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UmD0AW7KfbuR"
      },
      "id": "UmD0AW7KfbuR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "afffc5e3",
      "metadata": {
        "id": "afffc5e3"
      },
      "source": [
        "#### EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "ca3c1860",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca3c1860",
        "outputId": "b0ccf1be-7738-45f7-e614-21c107d06405"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/kaggle/input/rock-paper-scissors-dataset/Rock-Paper-Scissors\n",
            "/kaggle/input/rock-paper-scissors-dataset/rock-paper-scissors\n",
            "/kaggle/input/rock-paper-scissors-dataset/Rock-Paper-Scissors/validation\n",
            "/kaggle/input/rock-paper-scissors-dataset/Rock-Paper-Scissors/test\n",
            "/kaggle/input/rock-paper-scissors-dataset/Rock-Paper-Scissors/train\n",
            "/kaggle/input/rock-paper-scissors-dataset/Rock-Paper-Scissors/test/paper\n",
            "/kaggle/input/rock-paper-scissors-dataset/Rock-Paper-Scissors/test/rock\n",
            "/kaggle/input/rock-paper-scissors-dataset/Rock-Paper-Scissors/test/scissors\n",
            "/kaggle/input/rock-paper-scissors-dataset/Rock-Paper-Scissors/train/paper\n",
            "/kaggle/input/rock-paper-scissors-dataset/Rock-Paper-Scissors/train/rock\n",
            "/kaggle/input/rock-paper-scissors-dataset/Rock-Paper-Scissors/train/scissors\n",
            "/kaggle/input/rock-paper-scissors-dataset/rock-paper-scissors/Rock-Paper-Scissors\n",
            "/kaggle/input/rock-paper-scissors-dataset/rock-paper-scissors/Rock-Paper-Scissors/validation\n",
            "/kaggle/input/rock-paper-scissors-dataset/rock-paper-scissors/Rock-Paper-Scissors/test\n",
            "/kaggle/input/rock-paper-scissors-dataset/rock-paper-scissors/Rock-Paper-Scissors/train\n",
            "/kaggle/input/rock-paper-scissors-dataset/rock-paper-scissors/Rock-Paper-Scissors/test/paper\n",
            "/kaggle/input/rock-paper-scissors-dataset/rock-paper-scissors/Rock-Paper-Scissors/test/rock\n",
            "/kaggle/input/rock-paper-scissors-dataset/rock-paper-scissors/Rock-Paper-Scissors/test/scissors\n",
            "/kaggle/input/rock-paper-scissors-dataset/rock-paper-scissors/Rock-Paper-Scissors/train/paper\n",
            "/kaggle/input/rock-paper-scissors-dataset/rock-paper-scissors/Rock-Paper-Scissors/train/rock\n",
            "/kaggle/input/rock-paper-scissors-dataset/rock-paper-scissors/Rock-Paper-Scissors/train/scissors\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# path = \"/content/Rock-Paper-Scissors\"\n",
        "\n",
        "for root, dirs, files in os.walk(path):\n",
        "    for d in dirs:\n",
        "        print(os.path.join(root, d))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "8f8bf280",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f8bf280",
        "outputId": "54607c40-12fa-4e45-bdca-09a86fbaf6c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"train\": {\n",
            "    \"paper\": 840,\n",
            "    \"rock\": 840,\n",
            "    \"scissors\": 840,\n",
            "    \"total\": 2520\n",
            "  },\n",
            "  \"validation\": {\n",
            "    \"rock\": 11,\n",
            "    \"paper\": 11,\n",
            "    \"scissors\": 11,\n",
            "    \"total\": 33\n",
            "  },\n",
            "  \"test\": {\n",
            "    \"paper\": 124,\n",
            "    \"rock\": 124,\n",
            "    \"scissors\": 124,\n",
            "    \"total\": 372\n",
            "  },\n",
            "  \"overall_total\": 2925\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "root = Path(path) / \"Rock-Paper-Scissors\"\n",
        "splits = [\"train\", \"validation\", \"test\"]\n",
        "summary = {}\n",
        "\n",
        "for split in splits:\n",
        "    split_dir = root / split\n",
        "    summary[split] = {}\n",
        "    if split_dir.is_dir():\n",
        "        if any(child.is_dir() for child in split_dir.iterdir()):\n",
        "            # train/test\n",
        "            for cls_dir in sorted(split_dir.iterdir()):\n",
        "                if cls_dir.is_dir():\n",
        "                    summary[split][cls_dir.name] = len(list(cls_dir.glob(\"*.png\")))\n",
        "        else:\n",
        "            # validation\n",
        "            summary[split] = {\"rock\": 0, \"paper\": 0, \"scissors\": 0}\n",
        "            for img_path in split_dir.glob(\"*.png\"):\n",
        "                name = img_path.name.lower()\n",
        "                for cls in summary[split]:\n",
        "                    if cls in name:\n",
        "                        summary[split][cls] += 1\n",
        "                        break\n",
        "    summary[split][\"total\"] = sum(summary[split].values())\n",
        "\n",
        "summary[\"overall_total\"] = sum(summary[s][\"total\"] for s in splits)\n",
        "\n",
        "with open(\"data_summary.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(summary, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(json.dumps(summary, indent=2, ensure_ascii=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b98619ed",
      "metadata": {
        "id": "b98619ed"
      },
      "source": [
        "#### Clean Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "2c303cfa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c303cfa",
        "outputId": "0e242328-436b-4255-cd0a-c3a04d06e49f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2520 files belonging to 3 classes.\n",
            "Found 372 files belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "SEED = 77\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "SHUFFLE_BUFFER = 256\n",
        "PATH = path\n",
        "ROOT = root\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_ds_raw = tf.keras.utils.image_dataset_from_directory(\n",
        "    ROOT / \"train\",\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "test_ds_raw = tf.keras.utils.image_dataset_from_directory(\n",
        "    ROOT / \"test\",\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# Optimized Validation Pipeline (Pure TF)\n",
        "# ==========================================\n",
        "\n",
        "# 1. 解析路徑與標籤 (這部分在 Python 端只跑一次，生成 list，沒問題)\n",
        "label_map = {\"rock\": 0, \"paper\": 1, \"scissors\": 2}\n",
        "val_files = sorted((root / \"validation\").glob(\"*.png\"))\n",
        "\n",
        "val_path_strs = [str(p) for p in val_files]\n",
        "val_labels = []\n",
        "\n",
        "for p in val_files:\n",
        "    name = p.name.lower()\n",
        "    # 這裡的邏輯保持你原本的寫法，但建議檢查是否會有 unmatched 的情況\n",
        "    for cls_name, idx in label_map.items():\n",
        "        if cls_name in name:\n",
        "            val_labels.append(idx)\n",
        "            break\n",
        "    else:\n",
        "        # 處理異常情況，避免 label 對不齊\n",
        "        print(f\"Warning: No label found for {p.name}\")\n",
        "        val_labels.append(-1) # 標記錯誤\n",
        "\n",
        "# 2. 定義 Pure TF Loading Function\n",
        "def load_and_process_image(path, label):\n",
        "    # 使用 TF 原生 IO，不經過 Python Interpreter\n",
        "    img_raw = tf.io.read_file(path)\n",
        "    img = tf.io.decode_png(img_raw, channels=3)\n",
        "\n",
        "    # 這裡直接 Resize，確保記憶體中只持有小圖\n",
        "    img = tf.image.resize(img, IMG_SIZE)\n",
        "\n",
        "    # 轉換型別 (雖然 base_preprocess 會轉，但在這裡轉比較保險)\n",
        "    img = tf.cast(img, tf.float32)\n",
        "\n",
        "    return img, label\n",
        "\n",
        "# 3. 建構 Dataset\n",
        "val_ds_raw = tf.data.Dataset.from_tensor_slices((val_path_strs, val_labels))\n",
        "\n",
        "# 過濾掉無法標記的數據 (若有)\n",
        "val_ds_raw = val_ds_raw.filter(lambda x, y: y != -1)\n",
        "\n",
        "# 平行化處理 map\n",
        "val_ds_raw = val_ds_raw.map(load_and_process_image, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "# Batching (注意：這裡先不要 prefetch，統一在最後做)\n",
        "val_ds_raw = val_ds_raw.batch(BATCH_SIZE)\n",
        "\n",
        "# ==========================================\n",
        "# End of Optimization\n",
        "# =========================================="
      ],
      "metadata": {
        "id": "MKnyMFetYSdI"
      },
      "id": "MKnyMFetYSdI",
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6db266fb",
      "metadata": {
        "id": "6db266fb"
      },
      "source": [
        "#### Augumentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "73b7a696",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "73b7a696",
        "outputId": "46c59664-a41e-445f-8347-f9cf45b66490"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "in user code:\n\n    File \"/tmp/ipython-input-3588197059.py\", line 21, in initial_load  *\n        img = tf.io.read_file(path)\n\n    TypeError: Input 'filename' of 'ReadFile' Op has type float32 that does not match expected type of string.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3588197059.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0mval_ds\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_ds_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mtest_ds\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3588197059.py\u001b[0m in \u001b[0;36mpreprocess_dataset\u001b[0;34m(ds, training)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# 2. 關鍵時刻：Cache uint8 數據\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, synchronous, use_unbounded_threadpool, name)\u001b[0m\n\u001b[1;32m   2339\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmap_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2341\u001b[0;31m     return map_op._map_v2(\n\u001b[0m\u001b[1;32m   2342\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2343\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/map_op.py\u001b[0m in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, synchronous, use_unbounded_threadpool, name)\u001b[0m\n\u001b[1;32m     55\u001b[0m           \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m       )\n\u001b[0;32m---> 57\u001b[0;31m     return _ParallelMapDataset(\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/map_op.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, use_unbounded_threadpool, name)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m     self._map_func = structured_function.StructuredFunctionWrapper(\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1254\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m     \u001b[0;31m# Implements PolymorphicFunction.get_concrete_function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1256\u001b[0;31m     \u001b[0mconcrete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_garbage_collected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1257\u001b[0m     \u001b[0mconcrete\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1224\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m         \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1226\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1227\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_uninitialized_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     )\n\u001b[1;32m    695\u001b[0m     \u001b[0;31m# Force the definition of the function for these arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m     self._concrete_variable_creation_fn = tracing_compilation.trace_function(\n\u001b[0m\u001b[1;32m    697\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     concrete_function = _maybe_define_function(\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m           \u001b[0mtarget_func_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_func_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         concrete_function = _create_concrete_function(\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mtarget_func_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_func_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    308\u001b[0m       \u001b[0mattributes_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLE_ACD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m   )\n\u001b[0;32m--> 310\u001b[0;31m   traced_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    311\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m     \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    229\u001b[0m       \u001b[0;31m# Note: wrapper_helper will apply autograph based on context.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    159\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_variables_to_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_filedcasssl6.py\u001b[0m in \u001b[0;36mtf__initial_load\u001b[0;34m(path, label)\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_png\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/io_ops.py\u001b[0m in \u001b[0;36mread_file\u001b[0;34m(filename, name)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0mof\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m\"string\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfile\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m   \"\"\"\n\u001b[0;32m--> 134\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_io_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36mread_file\u001b[0;34m(filename, name)\u001b[0m\n\u001b[1;32m    586\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m    589\u001b[0m         \"ReadFile\", filename=filename, name=name)\n\u001b[1;32m    590\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    776\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m       _ExtractInputsAndAttrs(op_type_name, op_def, allowed_list_attr_map,\n\u001b[0m\u001b[1;32m    779\u001b[0m                              \u001b[0mkeywords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_type_attr_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m                              input_types)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_ExtractInputsAndAttrs\u001b[0;34m(op_type_name, op_def, allowed_list_attr_map, keywords, default_type_attr_map, attrs, inputs, input_types)\u001b[0m\n\u001b[1;32m    576\u001b[0m                   (input_name, op_type_name, observed))\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtypes_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDT_INVALID\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m           raise TypeError(f\"{prefix} expected type of \"\n\u001b[0m\u001b[1;32m    579\u001b[0m                           f\"{dtypes.as_dtype(input_arg.type).name}.\")\n\u001b[1;32m    580\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/tmp/ipython-input-3588197059.py\", line 21, in initial_load  *\n        img = tf.io.read_file(path)\n\n    TypeError: Input 'filename' of 'ReadFile' Op has type float32 that does not match expected type of string.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "base_preprocess = tf.keras.Sequential([\n",
        "    tf.keras.layers.Resizing(*IMG_SIZE),\n",
        "    tf.keras.layers.Rescaling(1./255, dtype=tf.float32),\n",
        "], name=\"base_preprocess\")\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomRotation(0.1),\n",
        "    tf.keras.layers.RandomZoom(0.1),\n",
        "    tf.keras.layers.RandomContrast(0.15),\n",
        "    tf.keras.layers.RandomBrightness(factor=0.1),\n",
        "], name=\"data_augmentation\")\n",
        "\n",
        "\n",
        "def preprocess_dataset(ds, training=False):\n",
        "    # 1. 第一階段：只做 Resize，保持 uint8 (0-255)\n",
        "    # 移除 Rescaling，確保 Tensor 還是 uint8\n",
        "    def initial_load(path, label):\n",
        "        img = tf.io.read_file(path)\n",
        "        img = tf.io.decode_png(img, channels=3)\n",
        "        img = tf.image.resize(img, IMG_SIZE)\n",
        "        # resize 預設輸出 float32，我們強轉回 uint8 省記憶體\n",
        "        img = tf.cast(img, tf.uint8)\n",
        "        return img, label\n",
        "\n",
        "    ds = ds.map(initial_load, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "    # 2. 關鍵時刻：Cache uint8 數據\n",
        "    # 此時記憶體佔用量只有 float32 版本的 1/4\n",
        "    ds = ds.cache()\n",
        "\n",
        "    # 3. 第二階段：即時轉換 (On-the-fly casting)\n",
        "    # 從 Cache 拿出來後，再轉成 float32 並歸一化\n",
        "    def subsequent_process(img, label):\n",
        "        img = tf.cast(img, tf.float32)\n",
        "        img = img / 255.0  # 手動 Rescaling\n",
        "        return img, label\n",
        "\n",
        "    ds = ds.map(subsequent_process, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "    if training:\n",
        "        ds = ds.shuffle(SHUFFLE_BUFFER)\n",
        "        # Augmentation 這裡會自動處理 float32\n",
        "        ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y),\n",
        "                    num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "    return ds.prefetch(AUTOTUNE)\n",
        "\n",
        "\n",
        "train_ds = preprocess_dataset(train_ds_raw, training=True)\n",
        "val_ds   = preprocess_dataset(val_ds_raw)\n",
        "test_ds  = preprocess_dataset(test_ds_raw)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d31633b4",
      "metadata": {
        "id": "d31633b4"
      },
      "source": [
        "#### Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0f94c9f",
      "metadata": {
        "id": "a0f94c9f"
      },
      "outputs": [],
      "source": [
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "def build_scratch_model(input_shape=(224, 224,3), num_classes=3):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    x = tf.keras.layers.Conv2D(24, 3, padding=\"same\")(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    x = tf.keras.layers.MaxPool2D()(x)\n",
        "\n",
        "    for filters in [64, 128, 256, 512]:\n",
        "        x = tf.keras.layers.Conv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        x = tf.keras.layers.ReLU()(x)\n",
        "        x = tf.keras.layers.Conv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        x = tf.keras.layers.ReLU()(x)\n",
        "        x = tf.keras.layers.MaxPool2D()(x)\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.Dropout(0.4)(x)\n",
        "    outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "    return tf.keras.Model(inputs, outputs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1b75a0d",
      "metadata": {
        "id": "a1b75a0d"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f02982b4",
      "metadata": {
        "id": "f02982b4"
      },
      "outputs": [],
      "source": [
        "model = build_scratch_model()\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=2e-3),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=[\"accuracy\"],\n",
        "    jit_compile=True\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"scratch_best.keras\",\n",
        "                                       monitor=\"val_accuracy\",\n",
        "                                       save_best_only=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-5),\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\", patience=6, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=40,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8052c1cd",
      "metadata": {
        "id": "8052c1cd"
      },
      "source": [
        "#### Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5760465d",
      "metadata": {
        "id": "5760465d"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history[\"loss\"], label=\"train\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"val\")\n",
        "plt.title(\"Loss\"); plt.legend()\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history[\"accuracy\"], label=\"train\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label=\"val\")\n",
        "plt.title(\"Accuracy\"); plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e2ecbfd",
      "metadata": {
        "id": "3e2ecbfd"
      },
      "outputs": [],
      "source": [
        "import seanborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_ds)\n",
        "print(f\"Test acc: {test_acc:.3f}\")\n",
        "\n",
        "y_true, y_pred = [], []\n",
        "for imgs, labels in test_ds:\n",
        "    probs = model.predict(imgs, verbose=0)\n",
        "    y_true.extend(labels.numpy())\n",
        "    y_pred.extend(np.argmax(probs, axis=1))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=label_map.keys(),\n",
        "            yticklabels=label_map.keys())\n",
        "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.show()\n",
        "print(classification_report(y_true, y_pred, target_names=list(label_map.keys())))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9b9fc91",
      "metadata": {
        "id": "a9b9fc91"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}